{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving ground-truth data to n5 containers\n",
    "\n",
    "This notebook transfers ground-truth data from h5 files to the centralized n5 container for each dataset, adding relevant metadata (resolution and offset in nm). The ground-truth data is added to the main n5 containers under the following path:  \n",
    "`volumes/groundtruth/{version}/{crop_name}`  \n",
    "where `version` starts at `0003` as per Larissa's instruction. Versioning the ground-truth data will enable corresponding versioning of networks.\n",
    "\n",
    "\n",
    "Additionally, this notebook performs a one-time adjustment of the organization of the n5 containers: \n",
    "\n",
    "`volumes/mask/{background_data}`  \n",
    "will become  \n",
    "`volumes/masks/groundtruth/{mask_data}`  \n",
    "`volumes/masks/foreground/{mask_data}`.    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# start with cell3\n",
    "# attributes.json include offsets, use bigcat format\n",
    "# attributes['offset'] = [x,y,z]\n",
    "# look at cremi specification \n",
    "z['volumes/groundtruth/{version}/crop{x}']\n",
    "z['volumes/masks/groundtruth']\n",
    "z['volumes/masks/background']\n",
    "# function to compute probability map from a crop\n",
    "# f(network_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fst.io import read\n",
    "from glob import glob\n",
    "\n",
    "def digest_annotated_data(fname, resolution_raw=4):\n",
    "    # Infer metadata from the filename, extract the data, return data and a dict of attributes.\n",
    "    import re\n",
    "    import numpy as np\n",
    "    from fst.io import read\n",
    "    crop_name_pattern = r'Crop\\d{1,}'\n",
    "    dims_pattern = r'\\d{1,}x\\d{1,}x\\d{1,}'\n",
    "    offset_pattern = r'[\\+,-]\\d{1,}[\\+,-]\\d{1,}[\\+,-]\\d{1,}'\n",
    "    label_dset_name = '/volumes/labels/gt'\n",
    "    \n",
    "    crop_name = re.search(crop_name_pattern, fname).group(0)\n",
    "    dims = np.array(re.search(dims_pattern, fname).group(0).split('x')).astype('int')    \n",
    "    padded_offset = np.array(re.split('[\\+,-]', re.search(offset_pattern, fname).group(0)[1:])).astype('int')\n",
    "    pad_width = ((read(fname)['/volumes/labels/gt'].attrs['offset'] + 1) / 4).astype('int')\n",
    "    offset_native_res = np.abs((padded_offset - pad_width))\n",
    "    data = read(f'{fname}:{label_dset_name}')[:]\n",
    "    \n",
    "    offset_nm = offset_native_res / resolution_raw\n",
    "    \n",
    "    resolution_nm = resolution_raw / (np.array(data.shape) / (dims - 2 * pad_width))\n",
    "    \n",
    "    resdict = dict(unit= 'nm', dimensions=resolution_nm.tolist())\n",
    "    attrs = {}\n",
    "    attrs['name'] = crop_name\n",
    "    attrs['offset'] = offset_nm.tolist()\n",
    "    attrs['pixelResolution'] = resdict\n",
    "        \n",
    "    return data, attrs\n",
    "\n",
    "def append_dataset(container_path, dataset_path, data, attrs=None):\n",
    "    # Add a new array to an existing n5 container using chunking / compression parameters from an existing array.\n",
    "    import numcodecs\n",
    "    import zarr\n",
    "    from fst.io import read, chmodr\n",
    "    # inherit the chunking scheme and compressor\n",
    "    template_path = 'volumes/raw'\n",
    "    template = read(container_path)[template_path]\n",
    "    compressor = numcodecs.GZip(level=template.compressor.compressor_config['level'])\n",
    "      \n",
    "    array = zarr.open(store=zarr.N5Store(container_path), \n",
    "                      path=dataset_path, \n",
    "                      chunks=template.chunks, \n",
    "                      compressor=compressor,\n",
    "                      shape=data.shape, \n",
    "                      mode='w', \n",
    "                      dtype=data.dtype)  \n",
    "    \n",
    "    array[:] = data\n",
    "    array.attrs.update(**attrs)\n",
    "    # this is ugly but saved time. \n",
    "    chmodr(container_path + '/volumes/' + dataset_path.split('/')[1], mode='umask') \n",
    "    return array\n",
    "\n",
    "def move_dataset(container_path, src, dest):\n",
    "    # use directory operations to relocate an n5 dataset within the container\n",
    "    import shutil\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    src_path = str(Path(container_path) / Path(src))\n",
    "    dest_path = str(Path(container_path) / Path(dest))\n",
    "    dest_parent = Path(dest_path).parent\n",
    "    if not os.path.exists(dest_parent):\n",
    "        os.makedirs(dest_parent)\n",
    "    result = shutil.move(src_path, dest_path)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob('~/dm11_cosem/annotations/bigcat/HeLa_Cell3*/*HeLa_Cell3*.h5')\n",
    "crop_version = '0003'\n",
    "for fn in fnames:\n",
    "    data, attrs = digest_annotated_data(fn)\n",
    "    crop_name = attrs['name']\n",
    "    arr = append_dataset('nrs_cosem/davis/HeLa_Cell3_4x4x4nm.n5', \n",
    "                         f'volumes/groundtruth/{crop_version}/{crop_name}', \n",
    "                         data=data, \n",
    "                         attrs=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zarr.core.Array '/volumes/groundtruth/0003/Crop33' (400, 400, 400) uint64 read-only>\n",
      "[('name', 'Crop33'), ('offset', [734.5, 57.5, 1284.5]), ('pixelResolution', {'dimensions': [2.0, 2.0, 2.0], 'unit': 'nm'})]\n"
     ]
    }
   ],
   "source": [
    "# these results look sane\n",
    "arr = read('/home/bennettd/nrs_cosem/davis/HeLa_Cell3_4x4x4nm.n5:/volumes/groundtruth/0003/Crop33')\n",
    "print(arr)\n",
    "print(list(arr.attrs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: Create ground-truth masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gt_mask(container_path, dest_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test moving datasets around within a container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/volumes/raw/subraw/ch1' (2784, 1000, 8750) uint8 read-only>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read('/home/bennettd/nrs_cosem/davis/test.n5/volumes/raw/subraw/ch1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bennettd/nrs_cosem/davis/test.n5/volumes/raw/ch1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_dataset('/home/bennettd/nrs_cosem/davis/test.n5', 'volumes/raw/subraw/ch1', 'volumes/raw/ch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/volumes/raw/ch1' (2784, 1000, 8750) uint8 read-only>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read('/home/bennettd/nrs_cosem/davis/test.n5/volumes/raw/ch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move extant mask datasets from `volumes/mask` to `volumes/masks/foreground` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bennettd/dm11_cosem/data/Jurkat_Cell1_4x4x4nm/Jurkat_Cell1_FS96-Area1_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/Pancreas_Islets_4x4x4m/Pancreas_G36-2_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/U2OS_Cell4_8x8x8nm/Cryo_LoadID252_Cell4_8x8x8nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/HeLa_Cell2_4x4x4nm/HeLa_Cell2_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/U2OS_Cell6_8x8x8nm/Cryo_LoadID253_Cell6_8x8x8nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/Chlamydomonas_4x4x4nm/Chlamydomonas_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/HeLa_Cell3_4x4x4nm/HeLa_Cell3_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/TWalther_WT45_Cell2_4x4x4nm/Cryo_20171009_WT45_Cell2_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/HeLa_Cell25_8x8x8nm/HeLa_Cell25_flat_8x8x8nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/Macrophage_FS80_Cell2_4x4x4nm/Cryo_FS80_Cell2_4x4x4nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/HeLa_Cell21_8x8x8nm/HeLa_Cell21_8x8x8nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/HeLa_Cell1_8x8x8nm/HeLa_Cell1_D05-10_8x8x8nm.n5',\n",
       " '/home/bennettd/dm11_cosem/data/Mouse_NA3-3_4x4x4nm/Mouse_NA3-3_4x4x4nm.n5']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containers = glob('/home/bennettd/dm11_cosem/data/*/*nm.n5')\n",
    "containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not work for /home/bennettd/dm11_cosem/data/Jurkat_Cell1_4x4x4nm/Jurkat_Cell1_FS96-Area1_4x4x4nm.n5\n",
      "Did not work for /home/bennettd/dm11_cosem/data/Pancreas_Islets_4x4x4m/Pancreas_G36-2_4x4x4nm.n5\n",
      "Did not work for /home/bennettd/dm11_cosem/data/Mouse_NA3-3_4x4x4nm/Mouse_NA3-3_4x4x4nm.n5\n"
     ]
    }
   ],
   "source": [
    "# when uncommented, this will do the move for all of the above containers\n",
    "for c in containers:\n",
    "    try:\n",
    "        move_dataset(c, 'volumes/mask', 'volumes/masks/foreground')\n",
    "    except:\n",
    "        print(f'Did not work for {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/volumes/masks/foreground' (4280, 1500, 5000) uint8 read-only>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read('/home/bennettd/dm11_cosem/data/Jurkat_Cell1_4x4x4nm/Jurkat_Cell1_FS96-Area1_4x4x4nm.n5/volumes/masks/foreground')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
